{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6dc949-1197-41a8-9170-720ded32480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###This script parses through the BLASTn output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7d38cb-f998-4474-a4c4-eeed28543d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfe7296e-2f44-451c-b9a0-2811f9597048",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Make a list of all samples\n",
    "samples = []\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/Mapping_v4_allfc_mod.txt\", \"r\"):\n",
    "    line = line.strip()\n",
    "    samples.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89213dcf-68c1-4188-b46c-f1167a47a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Make a dictionary of dictionaries enumerating the number of fragments found shared between two samples\n",
    "sharedElements = {}\n",
    "\n",
    "for query in samples:\n",
    "    sharedElements[query] = {}\n",
    "    for subject in samples:\n",
    "        if query != subject:\n",
    "            sharedElements[query][subject] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa4ab1f-119d-41f3-bcab-d955d34e071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    input_file = \"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_samples/BLASTn/filtered/filtered_\" + sample + \".txt\"\n",
    "    for line in open(input_file, \"r\"):\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        subject = line[1].split(\"_\")[0]\n",
    "        sharedElements[sample][subject] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f7781b-3c4f-42c3-9232-01ac695885e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharedElements_path = \"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_samples/BLASTn/221004_ShareElementsCounts.txt\"\n",
    "sharedElements_file = open(sharedElements_path, \"w\")\n",
    "\n",
    "print(\"Query\\tSubject\\tCount\", file = sharedElements_file)\n",
    "\n",
    "for query in sharedElements.keys():\n",
    "    for subject, count in sharedElements[query].items():\n",
    "        print(query + \"\\t\" + subject + \"\\t\" + str(count), file = sharedElements_file)\n",
    "        \n",
    "sharedElements_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3e7656-cdd2-4f76-b316-20e2b78544d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharedElements_condensed = {}\n",
    "\n",
    "for query in sharedElements.keys():\n",
    "    for subject in sharedElements[query].keys():\n",
    "        combo = query + \"\\t\" + subject\n",
    "        combo_alt = subject + \"\\t\" + query\n",
    "        if combo not in sharedElements_condensed.keys() and combo_alt not in sharedElements_condensed.keys():\n",
    "            mean = (sharedElements[query][subject] + sharedElements[subject][query])/2\n",
    "            sharedElements_condensed[combo] = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e293231-677f-4bc5-9181-a5b1cdb54933",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharedElements_condensed_path = \"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_samples/BLASTn/221004_ShareElementsCounts_condensed.txt\"\n",
    "sharedElements_condensed_file = open(sharedElements_condensed_path, \"w\")\n",
    "\n",
    "print(\"Sample1\\tSample2\\tCount\", file = sharedElements_condensed_file)\n",
    "\n",
    "for key, value in sharedElements_condensed.items():\n",
    "    print(key + \"\\t\" + str(value), file = sharedElements_condensed_file)\n",
    "    \n",
    "sharedElements_condensed_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d14545e-bc1e-478b-b6b0-431c11bd5cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Doing the same as above, but for HQ and MQ MAGs\n",
    "###First, getting a list of all MAGs\n",
    "MAGs = []\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/Mapping_v9_allHQandMQ-MAGs.txt\", \"r\"):\n",
    "    line = line.strip()\n",
    "    MAGs.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac9611d4-a9a5-4a13-b78e-28f4e82940f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Making a dictionary of contigs and which MAG they came from\n",
    "contigMAGs = {}\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d07_bin/dastool/HQandMQ_MAGs/MAGcontigs_map.txt\", \"r\"):\n",
    "    if line.startswith(\"Contig\"):\n",
    "        continue\n",
    "    else:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        contig = line[0]\n",
    "        MAG = line[1]\n",
    "        \n",
    "        contigMAGs[contig] = MAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4a1612a-7fe5-4191-aa4e-d08b343a45ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Getting the filtered fastANI values\n",
    "fastANI_MAGs = {}\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d28_fastani_HQMQ/fastani_out_filtered.txt\", \"r\"):\n",
    "    line = line.strip().split(\"\\t\")\n",
    "\n",
    "    MAG1 = line[0]\n",
    "    MAG2 = line[1]\n",
    "    score = float(line[2])\n",
    "    \n",
    "    key = MAG1 + \"-\" + MAG2\n",
    "    \n",
    "    fastANI_MAGs[key] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58e6f36a-dcb1-41c1-bdec-d8ea15acabaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Making a dictionary of the MAG qualities (HQ vs MQ)\n",
    "HQ_MAGs = []\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d07_bin/dastool/HQandMQ_MAGs/all_HQ_MAGs.txt\", \"r\"):\n",
    "    line = line.strip().split(\".\")[0]\n",
    "    HQ_MAGs.append(line)\n",
    "\n",
    "MQ_MAGs = []\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d07_bin/dastool/HQandMQ_MAGs/all_HQandMQ_MAGs.txt\", \"r\"):\n",
    "    line = line.strip().split(\".\")[0]\n",
    "    if line not in HQ_MAGs:\n",
    "        MQ_MAGs.append(line)\n",
    "        \n",
    "MAG_quality = {}\n",
    "\n",
    "for item in HQ_MAGs:\n",
    "    MAG_quality[item] = \"HQ\"\n",
    "    \n",
    "for item in MQ_MAGs:\n",
    "    MAG_quality[item] = \"MQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81468bcd-f932-40a9-be87-5d163699fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Making a dictionary of the taxanomic classification of the MAGs\n",
    "MAG_taxa = {}\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d07_bin/dastool/HQandMQ_MAGs/joint_classify.txt\", \"r\"):\n",
    "    line = line.strip()\n",
    "    line = line.split(\"\\t\")\n",
    "    \n",
    "    MAG = line[0]\n",
    "    tax = line[1]\n",
    "    \n",
    "    MAG_taxa[MAG] = tax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d17e2324-8dc5-4bb4-b295-035cea9003e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Making a dictionary of the subject of origins of MAGs\n",
    "MAG_subjects = {}\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d07_bin/dastool/allbins_noUnbin/MAG_subjects.txt\", \"r\"):\n",
    "    line = line.strip().split(\"\\t\")\n",
    "    MAG = line[0].split(\".\")[0]\n",
    "    subject = line[1]\n",
    "    \n",
    "    if MAG in MAGs:\n",
    "        MAG_subjects[MAG] = subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "065184f8-703c-4801-80d1-f2f1d7af1060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4884 and 993 and 3891\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(MAG_subjects)} and {len(HQ_MAGs)} and {len(MQ_MAGs)}')\n",
    "#len(HQ_MAGs)\n",
    "#len(MQ_MAGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef68c68-0bb6-40b4-90fe-bf08fdfddf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Filtering the BLASTn results to remove duplicate MAG pairs\n",
    "###This was taking forever, so ran through cluster\n",
    "pairs = []\n",
    "\n",
    "BLASTn_nodup_file = open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup.txt\", \"w\")\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs.txt\"):\n",
    "    line = line.strip()\n",
    "    contig1 = line.split(\"\\t\")[0]\n",
    "    contig2 = line.split(\"\\t\")[1]\n",
    "    \n",
    "    pair = [contig1, contig2]\n",
    "    pair.sort()\n",
    "    \n",
    "    combo = pair[0] + \"-\" + pair[1]\n",
    "    \n",
    "    if combo not in pairs:\n",
    "        pairs.append(combo)\n",
    "        print(line, file = BLASTn_nodup_file)\n",
    "\n",
    "BLASTn_nodup_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7118d278-cddc-47f3-a1b4-d25fd42d2920",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Going through the filtered (nodup) list of hits to get the MAG, subject, and ANI information\n",
    "BLASTn_annot  = open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot.txt\", \"w\")\n",
    "\n",
    "for line in open (\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_BK.txt\"):\n",
    "    line = line.strip()\n",
    "    contig1 = line.split(\"\\t\")[0]\n",
    "    contig2 = line.split(\"\\t\")[1]\n",
    "    \n",
    "    MAG1 = contigMAGs[contig1]\n",
    "    MAG2 = contigMAGs[contig2]\n",
    "    \n",
    "    subject1 = contig1.split(\"_\")[0]\n",
    "    subject2 = contig2.split(\"_\")[0]\n",
    "    \n",
    "    combo = str(min(int(MAG1), int(MAG2))) + \"-\" + str(max(int(MAG1), int(MAG2)))\n",
    "    \n",
    "    if combo in fastANI_MAGs.keys():\n",
    "        ANI = str(fastANI_MAGs[combo])\n",
    "    else:\n",
    "        ANI = \"0\"\n",
    "        \n",
    "    print(line + \"\\t\" + MAG1 + \"\\t\" + MAG2 + \"\\t\" + subject1 + \"\\t\" + subject2 + \"\\t\" + ANI, file = BLASTn_annot)\n",
    "    \n",
    "BLASTn_annot.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d556c9d3-5959-4d01-b303-0fec71ab0516",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Filtering through the teh annotated BLASTn hits list to filter out unneeded hits (i.e., ANI > 95%, same contig, same MAG)\n",
    "BLASTn_filtered = open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt.txt\", \"w\")\n",
    "\n",
    "print(\"Contig1\\tContig2\\tpident\\tlength\\tmismatch\\tgapopen\\tqstart\\tqend\\tsstart\\tsend\\tevalue\\tbitscore\\tMAG1\\tMAG2\\tMAGqual1\\tMAGqual2\\tSubject1\\tSubject2\\tHostPair\\tANI\", file = BLASTn_filtered)\n",
    "\n",
    "for line in open (\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_BK.txt\"):\n",
    "    line = line.strip()\n",
    "    contig1 = line.split(\"\\t\")[0]\n",
    "    contig2 = line.split(\"\\t\")[1]\n",
    "    \n",
    "    MAG1 = contigMAGs[contig1]\n",
    "    MAG2 = contigMAGs[contig2]\n",
    "    \n",
    "    qual1 = MAG_quality[MAG1]\n",
    "    qual2 = MAG_quality[MAG2]\n",
    "    \n",
    "    subject1 = contig1.split(\"_\")[0]\n",
    "    subject2 = contig2.split(\"_\")[0]\n",
    "    \n",
    "    host_pair = [subject1[0], subject2[0]]\n",
    "    host_pair.sort()\n",
    "    host_pair = host_pair[0] + \"-\" + host_pair[1]\n",
    "    \n",
    "    combo = str(min(int(MAG1), int(MAG2))) + \"-\" + str(max(int(MAG1), int(MAG2)))\n",
    "    \n",
    "    if combo in fastANI_MAGs.keys():\n",
    "        ANI = str(fastANI_MAGs[combo])\n",
    "    else:\n",
    "        ANI = \"0\"\n",
    "    \n",
    "    spec1 = MAG_taxa[MAG1]\n",
    "    spec1 = spec1.split(\"\\t\")[-1]\n",
    "    spec2 = MAG_taxa[MAG2]\n",
    "    spec2 = spec2.split(\"\\t\")[-1]\n",
    "    \n",
    "    same_spec = False\n",
    "    \n",
    "    if spec1 == spec2 and spec1 != \"s__\":\n",
    "        same_spec = True\n",
    "    \n",
    "    \n",
    "    if contig1 != contig2 and MAG1 != MAG2 and float(ANI) < 95 and same_spec == False:\n",
    "        print(line + \"\\t\" + MAG1 + \"\\t\" + MAG2 + \"\\t\" + qual1 + \"\\t\" + qual2 + \"\\t\" + subject1 + \"\\t\" + subject2 + \"\\t\" + host_pair + \"\\t\" + ANI, file = BLASTn_filtered)\n",
    "    \n",
    "BLASTn_filtered.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa09af2d-33b6-4a1a-a01c-0b1800d434f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Looking to see how many pairs of MAGs that are not the same species are possible\n",
    "cow_MAGs = []\n",
    "farmer_MAGs = []\n",
    "office_MAGs = []\n",
    "\n",
    "for MAG in MAGs:\n",
    "    if MAG_subjects[MAG].startswith(\"C\"):\n",
    "        cow_MAGs.append(MAG)\n",
    "    elif MAG_subjects[MAG].startswith(\"W\"):\n",
    "        farmer_MAGs.append(MAG)\n",
    "    elif MAG_subjects[MAG].startswith(\"D\"):\n",
    "        office_MAGs.append(MAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c6c01-c18b-43b7-a771-622718d3b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cow_farmer_combo = []\n",
    "\n",
    "cow_office_combo = []\n",
    "\n",
    "for MAG1 in cow_MAGs:\n",
    "    for MAG2 in farmer_MAGs:\n",
    "        cow_farmer_combo.append(MAG1 + \"-\" + MAG2)\n",
    "        \n",
    "for MAG1 in cow_MAGs:\n",
    "    for MAG2 in office_MAGs:\n",
    "        cow_office_combo.append(MAG1 + \"-\" + MAG2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753a68e9-1caf-4f81-908b-11dd8008f325",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for entry in cow_farmer_combo:\n",
    "    MAG1 = entry.split(\"-\")[0]\n",
    "    MAG2 = entry.split(\"-\")[1]\n",
    "    \n",
    "    combo = str(min(int(MAG1), int(MAG2))) + \"-\" + str(max(int(MAG1), int(MAG2)))\n",
    "    \n",
    "    if combo in fastANI_MAGs.keys():\n",
    "        ANI = fastANI_MAGs[combo]\n",
    "    else:\n",
    "        ANI = 0\n",
    "        \n",
    "    spec1 = MAG_taxa[MAG1]\n",
    "    spec1 = spec1.split(\"\\t\")[-1]\n",
    "    spec2 = MAG_taxa[MAG2]\n",
    "    spec2 = spec2.split(\"\\t\")[-1]\n",
    "    \n",
    "    same_spec = False\n",
    "    \n",
    "    if spec1 == spec2 and spec1 != \"s__\":\n",
    "        same_spec = True\n",
    "        \n",
    "    if ANI > 95 or same_spec == True:\n",
    "        counter += 1\n",
    "            \n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36ca786-3181-4cdc-b8c9-d0cd1a92f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for entry in cow_office_combo:\n",
    "    MAG1 = entry.split(\"-\")[0]\n",
    "    MAG2 = entry.split(\"-\")[1]\n",
    "    \n",
    "    combo = str(min(int(MAG1), int(MAG2))) + \"-\" + str(max(int(MAG1), int(MAG2)))\n",
    "    \n",
    "    if combo in fastANI_MAGs.keys():\n",
    "        ANI = fastANI_MAGs[combo]\n",
    "    else:\n",
    "        ANI = 0\n",
    "        \n",
    "    spec1 = MAG_taxa[MAG1]\n",
    "    spec1 = spec1.split(\"\\t\")[-1]\n",
    "    spec2 = MAG_taxa[MAG2]\n",
    "    spec2 = spec2.split(\"\\t\")[-1]\n",
    "    \n",
    "    same_spec = False\n",
    "    \n",
    "    if spec1 == spec2 and spec1 != \"s__\":\n",
    "        same_spec = True\n",
    "        \n",
    "    if ANI > 95 or same_spec == True:\n",
    "        counter += 1\n",
    "            \n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e7b62-4dd9-4d83-b262-e6f2a462806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for key, value in fastANI_MAGs.items():\n",
    "    MAG1 = key.split(\"-\")[0]\n",
    "    MAG2 = key.split(\"-\")[1]\n",
    "    \n",
    "    if MAG_subjects[MAG1].startswith(\"C\") and MAG_subjects[MAG2].startswith(\"W\") and value >= 95:\n",
    "        counter += 1\n",
    "    elif MAG_subjects[MAG1].startswith(\"W\") and MAG_subjects[MAG2].startswith(\"C\") and value >= 95:\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23e4570-02a0-4542-bdbe-f5b62c82729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for MAG in office_MAGs:\n",
    "    if MAG_quality[MAG] == \"HQ\":\n",
    "        counter += 1\n",
    "        \n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7b73d6-197d-495b-98f9-834c2d9f14ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Going through the list of the identified BLAST hits to see which ones include ARGs\n",
    "###First, creating a dictionaries of the ARG coordinates of the contigs\n",
    "contig_ARGcoordinates = {}\n",
    "contig_ARGannot = {}\n",
    "contig_ARGORFID = {}\n",
    "contig_abxClasses = {}\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d12_shortbred_HQMQ/230118_shortBRED_ORFID_contigs_v2.txt\", \"r\"):\n",
    "    if line.startswith(\"MAG\"):\n",
    "        continue\n",
    "    else:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        ORFID = line[1]\n",
    "        abxClass = line[2]\n",
    "        annot = line[3]\n",
    "        contig = line[4]\n",
    "        start = line[5]\n",
    "        stop = line[6]\n",
    "        \n",
    "        if contig in contig_ARGcoordinates.keys():\n",
    "            contig_ARGcoordinates[contig].append(start + \"\\t\" + stop)\n",
    "        else:\n",
    "            contig_ARGcoordinates[contig] = []\n",
    "            contig_ARGcoordinates[contig].append(start + \"\\t\" + stop)\n",
    "            \n",
    "        if contig in contig_ARGannot.keys():\n",
    "            contig_ARGannot[contig].append(annot)\n",
    "        else:\n",
    "            contig_ARGannot[contig] = []\n",
    "            contig_ARGannot[contig].append(annot)\n",
    "            \n",
    "        if contig in contig_abxClasses.keys():\n",
    "            contig_abxClasses[contig].append(abxClass)\n",
    "        else:\n",
    "            contig_abxClasses[contig] = []\n",
    "            contig_abxClasses[contig].append(abxClass)\n",
    "            \n",
    "        if contig in contig_ARGORFID.keys():\n",
    "            contig_ARGORFID[contig].append(ORFID)\n",
    "        else:\n",
    "            contig_ARGORFID[contig] = []\n",
    "            contig_ARGORFID[contig].append(ORFID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb92ecb-a6c0-45b6-9c67-47b773b9eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_hits = []\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt.txt\", \"r\"):\n",
    "    if line.startswith(\"Contig1\"):\n",
    "        continue\n",
    "    else:\n",
    "        line = line.strip()\n",
    "        if \"C-W\" in line:\n",
    "            CW_hits.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15847ad3-fde0-4495-8ba5-77bd9c62d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_hits_ARG = []\n",
    "\n",
    "for line in CW_hits:\n",
    "    contig1 = line.split(\"\\t\")[0]\n",
    "    contig2 = line.split(\"\\t\")[1]\n",
    "    \n",
    "    start1 = int(line.split(\"\\t\")[6])\n",
    "    stop1 = int(line.split(\"\\t\")[7])\n",
    "    \n",
    "    if start1 > stop1:\n",
    "        temp = start1\n",
    "        start1 = stop1\n",
    "        stop1 = temp\n",
    "        \n",
    "    start2 = int(line.split(\"\\t\")[8])\n",
    "    stop2 = int(line.split(\"\\t\")[9])\n",
    "    \n",
    "    if start2 > stop2:\n",
    "        temp = start2\n",
    "        start2 = stop2\n",
    "        stop2 = temp\n",
    "    \n",
    "    ARGs = \"\"\n",
    "    \n",
    "    if contig1 not in contig_ARGcoordinates.keys() and contig2 not in contig_ARGcoordinates.keys():\n",
    "        CW_hits_ARG.append(line + \"\\tNone\")\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        if contig1 in contig_ARGcoordinates.keys():\n",
    "            for i in range(len(contig_ARGcoordinates[contig1])):\n",
    "                start = int(contig_ARGcoordinates[contig1][i].split(\"\\t\")[0])\n",
    "                stop = int(contig_ARGcoordinates[contig1][i].split(\"\\t\")[1])\n",
    "                cov = 0\n",
    "\n",
    "                if start > stop:\n",
    "                    temp = start\n",
    "                    start = stop\n",
    "                    stop = temp\n",
    "\n",
    "                if start > start1 and start < stop1 and stop > start1 and stop < stop1:\n",
    "                    cov = 100\n",
    "                elif start > start1 and start < stop1 and stop > start1 and stop > stop1:\n",
    "                    cov = (stop1 - start)/(stop - start)\n",
    "                    cov = round(cov * 100)\n",
    "                elif start < start1 and start < stop1 and stop > start1 and stop < stop1:\n",
    "                    cov = (stop - start1)/(stop - start)\n",
    "                    cov = round(cov * 100)\n",
    "                elif start < start1 and start < stop1 and stop > start1 and stop > stop1:\n",
    "                    cov = (stop1 - start1)/(stop - start)\n",
    "                    cov = round(cov * 100)\n",
    "                else:\n",
    "                    cov = 0\n",
    "                    \n",
    "                if cov == 100:\n",
    "                    if ARGs == \"\":\n",
    "                        ARGs = contig1 + \",\" + contig_abxClasses[contig1][i] + \",\" + contig_ARGannot[contig1][i] + \",\" + str(cov)\n",
    "                    else:\n",
    "                        ARGs = ARGs + \"\\t\" + contig1 + \",\" + contig_abxClasses[contig1][i] + \",\" + contig_ARGannot[contig1][i] + \",\" + str(cov)\n",
    "                        \n",
    "        if contig2 in contig_ARGcoordinates.keys():\n",
    "            for i in range(len(contig_ARGcoordinates[contig2])):\n",
    "                start = int(contig_ARGcoordinates[contig2][i].split(\"\\t\")[0])\n",
    "                stop = int(contig_ARGcoordinates[contig2][i].split(\"\\t\")[1])\n",
    "                cov = 0\n",
    "\n",
    "                if start > stop:\n",
    "                    temp = start\n",
    "                    start = stop\n",
    "                    stop = temp\n",
    "\n",
    "                if start > start2 and start < stop2 and stop > start2 and stop < stop2:\n",
    "                    cov = 100\n",
    "                elif start > start2 and start < stop2 and stop > start2 and stop > stop2:\n",
    "                    cov = (stop2 - start)/(stop - start)\n",
    "                    cov = round(cov * 100)\n",
    "                elif start < start2 and start < stop2 and stop > start2 and stop < stop2:\n",
    "                    cov = (stop - start2)/(stop - start)\n",
    "                    cov = round(cov * 100)\n",
    "                elif start < start2 and start < stop2 and stop > start2 and stop > stop2:\n",
    "                    cov = (stop2 - start2)/(stop - start)\n",
    "                    cov = round(cov * 100)\n",
    "                else:\n",
    "                    cov = 0\n",
    "                    \n",
    "                if cov == 100:\n",
    "                    if ARGs == \"\":\n",
    "                        ARGs = contig2 + \",\" + contig_abxClasses[contig2][i] + \",\" + contig_ARGannot[contig2][i] + \",\" + str(cov)\n",
    "                    else:\n",
    "                        ARGs = ARGs + \"\\t\" + contig2 + \",\" + contig_abxClasses[contig2][i] + \",\" + contig_ARGannot[contig2][i] + \",\" + str(cov)\n",
    "                        \n",
    "        if ARGs == \"\":\n",
    "            CW_hits_ARG.append(line + \"\\tNone\")\n",
    "        else:\n",
    "            CW_hits_ARG.append(line + \"\\t\" + ARGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25446fb-7f72-4e06-bcf3-ac496e1e1849",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_hits_ARG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b938ec99-00f6-4f8d-b53f-35bfc8ea2e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for line in CW_hits_ARG:\n",
    "    if line.split(\"\\t\")[-1] != \"None\":\n",
    "        counter += 1\n",
    "\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f491fad3-4f6e-4e26-9d67-732b2056fc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_hits_ARG_file = open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt_CW_ARGs_100cov.txt\", \"w\")\n",
    "\n",
    "print(\"Contig1\\tContig2\\tpident\\tlength\\tmismatch\\tgapopen\\tqstart\\tqend\\tsstart\\tsend\\tevalue\\tbitscore\\tMAG1\\tMAG2\\tMAGqual1\\tMAGqual2\\tSubject1\\tSubject2\\tHostPair\\tANI\\tARGs\", file = CW_hits_ARG_file)\n",
    "\n",
    "for line in CW_hits_ARG:\n",
    "    print(line.strip(), file = CW_hits_ARG_file)\n",
    "\n",
    "CW_hits_ARG_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf4f5c-6cc6-4c7f-a0d5-ad5b91c67fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###For many shared fragments, matching ARGs were identified from both the query and the subject, which is great and expected\n",
    "###Now going thorugh the entries to keep only unique ARG-matched ORFs for each BLAST hit\n",
    "CW_ARGs_unique = []\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt_CW_ARGs_100cov.txt\", \"r\"):\n",
    "    if line.startswith(\"Contig1\"):\n",
    "        continue\n",
    "    else:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        \n",
    "        contig1 = line[0]\n",
    "        contig2 = line[1]\n",
    "        \n",
    "        pident = line[2]\n",
    "        length = line[3]\n",
    "        \n",
    "        MAG1 = line[12]\n",
    "        MAG2 = line[13]\n",
    "        \n",
    "        taxa1 = MAG_taxa[MAG1]\n",
    "        taxa1 = taxa1.split(\";\")\n",
    "        domain1 = taxa1[0]\n",
    "        phylum1 = taxa1[1]\n",
    "        class1 = taxa1[2]\n",
    "        order1 = taxa1[3]\n",
    "        family1 = taxa1[4]\n",
    "        genus1 = taxa1[5]\n",
    "        species1 = taxa1[6]\n",
    "        \n",
    "        taxa2 = MAG_taxa[MAG2]\n",
    "        taxa2 = taxa2.split(\";\")\n",
    "        domain2 = taxa2[0]\n",
    "        phylum2 = taxa2[1]\n",
    "        class2 = taxa2[2]\n",
    "        order2 = taxa2[3]\n",
    "        family2 = taxa2[4]\n",
    "        genus2 = taxa2[5]\n",
    "        species2 = taxa2[6]\n",
    "        \n",
    "        if family1 == family2:\n",
    "            families = \"Same family\"\n",
    "        else:\n",
    "            families = \"Different families\"\n",
    "            \n",
    "        if genus1 == genus2:\n",
    "            genera = \"Same genera\"\n",
    "        else:\n",
    "            genera = \"Different genera\"\n",
    "        \n",
    "        subject1 = line[16]\n",
    "        subject2 = line[17]\n",
    "        \n",
    "        ARGs = line[20:]\n",
    "        \n",
    "        if line[-1] == \"None\":\n",
    "            CW_ARGs_unique.append(\"\\t\".join([contig1, contig2, pident, length, MAG1, MAG2, domain1, phylum1, class1, order1, family1, genus1, species1, domain2, phylum2, class2, order2, family2, genus2, species2, families, genera, subject1, subject2, line[-1]]))\n",
    "        else:\n",
    "            unique_ORFs = []\n",
    "            unique_entries = []\n",
    "            \n",
    "            for item in ARGs:\n",
    "                item = item.split(\",\")\n",
    "                ARGclass = item[1]\n",
    "                ORF = item[2]\n",
    "                if ORF not in unique_ORFs:\n",
    "                    unique_entries.append(ARGclass + \",\" + ORF)\n",
    "                    unique_ORFs.append(ORF)\n",
    "            \n",
    "            unique_entries = \"\\t\".join(unique_entries)\n",
    "            CW_ARGs_unique.append(\"\\t\".join([contig1, contig2, pident, length, MAG1, MAG2, domain1, phylum1, class1, order1, family1, genus1, species1, domain2, phylum2, class2, order2, family2, genus2, species2, families, genera, subject1, subject2, unique_entries]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df3a5b-7c9c-49ef-82e2-52214c6c145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_ARGs_unique_file = open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt_CW_ARGs_100cov_uniqueORFs.txt\", \"w\")\n",
    "CW_onlyARGs_unique_file = open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt_CW_onlyARGs_100cov_uniqueORFs.txt\", \"w\")\n",
    "\n",
    "print(\"Contig1\\tContig2\\tpident\\tlength\\tMAG1\\tMAG2\\tDomain1\\tPhylum1\\tClass1\\tOrder1\\tFamily1\\tGenus1\\tSpecies1\\tDomain2\\tPhylum2\\tClass2\\tOrder2\\tFamily2\\tGenus2\\tSpecies2\\tFamilies\\tGenera\\tSubject1\\tSubject2\\tARGs\", file = CW_ARGs_unique_file)\n",
    "print(\"Contig1\\tContig2\\tpident\\tlength\\tMAG1\\tMAG2\\tDomain1\\tPhylum1\\tClass1\\tOrder1\\tFamily1\\tGenus1\\tSpecies1\\tDomain2\\tPhylum2\\tClass2\\tOrder2\\tFamily2\\tGenus2\\tSpecies2\\tFamilies\\tGenera\\tSubject1\\tSubject2\\tARGs\", file = CW_onlyARGs_unique_file)\n",
    "\n",
    "for line in CW_ARGs_unique:\n",
    "    print(line, file = CW_ARGs_unique_file)\n",
    "    if line.split(\"\\t\")[-1] != \"None\":\n",
    "        print(line, file = CW_onlyARGs_unique_file)\n",
    "        \n",
    "CW_ARGs_unique_file.close()\n",
    "CW_onlyARGs_unique_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0326da-48a0-455a-9377-a97310f8dea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Looking at classes of abx which are represented by shared ARGs\n",
    "sharedAbxClasses = {}\n",
    "\n",
    "for line in CW_ARGs_unique:\n",
    "    if line.split(\"\\t\")[-1] != \"None\":\n",
    "        ARGs = line.split(\"\\t\")[24:]\n",
    "        for item in ARGs:\n",
    "            ARGclass = item.split(\",\")[0]\n",
    "            if ARGclass in sharedAbxClasses.keys():\n",
    "                sharedAbxClasses[ARGclass] += 1\n",
    "            else:\n",
    "                sharedAbxClasses[ARGclass] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c43db-8b90-417c-af51-c6b7bc949f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(sharedAbxClasses.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acd58ad-5ab0-44ac-8072-378eb9fc89ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Looking at ORFs that are encoded within the sared fragments to do GO-term analysis\n",
    "######First, creating a dictionary (MAGs) of dictionaries (contigs) where the info about encoded ORFs or releavant contigs is storred\n",
    "contig_ORFs = {}\n",
    "\n",
    "for line in CW_ARGs_unique:\n",
    "    line = line.split(\"\\t\")\n",
    "    MAG1 = line[4]\n",
    "    MAG2 = line[5]\n",
    "    \n",
    "    contig1 = line[0]\n",
    "    contig2 = line[1]\n",
    "    \n",
    "    if MAG1 not in contig_ORFs.keys():\n",
    "        contig_ORFs[MAG1] = {}\n",
    "        \n",
    "    if MAG2 not in contig_ORFs.keys():\n",
    "        contig_ORFs[MAG2] = {}\n",
    "        \n",
    "    if contig1 not in contig_ORFs[MAG1].keys():\n",
    "        contig_ORFs[MAG1][contig1] = []\n",
    "        \n",
    "    if contig2 not in contig_ORFs[MAG2].keys():\n",
    "        contig_ORFs[MAG2][contig2] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e031928a-910e-4c7a-b5e6-fad9aed82ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Bakta renames contigs, so generating a dictionary to link the new IDs to the old contig IDs\n",
    "contig_names = {}\n",
    "\n",
    "for MAG in contig_ORFs.keys():\n",
    "    contig_names[MAG] = {}\n",
    "\n",
    "    for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d25_bakta_HQMQ/\" + MAG + \"/\" + MAG + \".log\", \"r\"):\n",
    "        if \"INFO - UTILS - qc: revised sequence:\" in line:\n",
    "            line = line.strip().split(\" \")\n",
    "            newID = line[9][:-1].split(\"=\")[1]\n",
    "            oldID = line[10][:-1].split(\"=\")[1]\n",
    "            contig_names[MAG][oldID] = newID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff14620-38c2-4299-bcf2-71171c4e609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Now, getting the ORFs that are encoded in each of the relevant contigs\n",
    "for MAG in contig_ORFs.keys():\n",
    "    for contig in contig_ORFs[MAG].keys():\n",
    "        new_contig_name = contig_names[MAG][contig]\n",
    "        for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d25_bakta_HQMQ/\" + MAG + \"/\" + MAG + \".gff3\", \"r\"):\n",
    "            if line.startswith(new_contig_name) and \"region\" not in line:\n",
    "                line = line.strip().split(\"\\t\")\n",
    "                ORFtype = line[2]\n",
    "                start = line[3]\n",
    "                stop = line[4]\n",
    "                strand = line[6]\n",
    "                \n",
    "                ID = line[8].split(\";\")[0].split(\"=\")[1]\n",
    "                name = line[8].split(\";\")[1].split(\"=\")[1]\n",
    "                \n",
    "                entry = ORFtype + \"\\t\" + start + \"\\t\" + stop + \"\\t\" + strand + \"\\t\" + ID + \"\\t\" + name\n",
    "                \n",
    "                contig_ORFs[MAG][contig].append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e224b6-e88a-484c-9cfe-740bab3520b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Now going through each of the hits to see which ORFs are found within\n",
    "CW_hits_ORF = []\n",
    "\n",
    "for line in CW_hits:\n",
    "    contig1 = line.split(\"\\t\")[0]\n",
    "    contig2 = line.split(\"\\t\")[1]\n",
    "    \n",
    "    start1 = int(line.split(\"\\t\")[6])\n",
    "    stop1 = int(line.split(\"\\t\")[7])\n",
    "    \n",
    "    if start1 > stop1:\n",
    "        temp = start1\n",
    "        start1 = stop1\n",
    "        stop1 = temp\n",
    "        \n",
    "    start2 = int(line.split(\"\\t\")[8])\n",
    "    stop2 = int(line.split(\"\\t\")[9])\n",
    "    \n",
    "    if start2 > stop2:\n",
    "        temp = start2\n",
    "        start2 = stop2\n",
    "        stop2 = temp\n",
    "    \n",
    "    MAG1 = line.split(\"\\t\")[12]\n",
    "    MAG2 = line.split(\"\\t\")[13]\n",
    "    \n",
    "    ORFs = \"\"\n",
    "    \n",
    "    for i in range(len(contig_ORFs[MAG1][contig1])):\n",
    "        ORFtype = contig_ORFs[MAG1][contig1][i].split(\"\\t\")[0]\n",
    "        start = int(contig_ORFs[MAG1][contig1][i].split(\"\\t\")[1])\n",
    "        stop = int(contig_ORFs[MAG1][contig1][i].split(\"\\t\")[2])\n",
    "        ID = contig_ORFs[MAG1][contig1][i].split(\"\\t\")[4]\n",
    "        name = contig_ORFs[MAG1][contig1][i].split(\"\\t\")[5]\n",
    "        cov = 0\n",
    "\n",
    "        if start > stop:\n",
    "            temp = start\n",
    "            start = stop\n",
    "            stop = temp\n",
    "\n",
    "        if start > start1 and start < stop1 and stop > start1 and stop < stop1:\n",
    "            cov = 100\n",
    "\n",
    "        if cov == 100:\n",
    "            if ORFs == \"\":\n",
    "                ORFs = contig1 + \",\" + ORFtype + \",\" + ID + \",\" + name\n",
    "            else:\n",
    "                ORFs = ORFs + \"\\t\" + contig1 + \",\" + ORFtype + \",\" + ID + \",\" + name\n",
    "                        \n",
    "    for i in range(len(contig_ORFs[MAG2][contig2])):\n",
    "        ORFtype = contig_ORFs[MAG2][contig2][i].split(\"\\t\")[0]\n",
    "        start = int(contig_ORFs[MAG2][contig2][i].split(\"\\t\")[1])\n",
    "        stop = int(contig_ORFs[MAG2][contig2][i].split(\"\\t\")[2])\n",
    "        ID = contig_ORFs[MAG2][contig2][i].split(\"\\t\")[4]\n",
    "        name = contig_ORFs[MAG2][contig2][i].split(\"\\t\")[5]\n",
    "        cov = 0\n",
    "\n",
    "        if start > stop:\n",
    "            temp = start\n",
    "            start = stop\n",
    "            stop = temp\n",
    "\n",
    "        if start > start2 and start < stop2 and stop > start2 and stop < stop2:\n",
    "            cov = 100\n",
    "\n",
    "        if cov == 100:\n",
    "            if ORFs == \"\":\n",
    "                ORFs = contig2 + \",\" + ORFtype + \",\" + ID + \",\" + name\n",
    "            else:\n",
    "                ORFs = ORFs + \"\\t\" + contig2 + \",\" + ORFtype + \",\" + ID + \",\" + name\n",
    "                        \n",
    "    if ORFs == \"\":\n",
    "        CW_hits_ORF.append(line + \"\\tNone\")\n",
    "    else:\n",
    "        CW_hits_ORF.append(line + \"\\t\" + ORFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193f6079-3a55-407e-9fc8-67c9640c5101",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_hits_ORF_file = open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt_CW_ORFs_100cov.txt\", \"w\")\n",
    "\n",
    "print(\"Contig1\\tContig2\\tpident\\tlength\\tmismatch\\tgapopen\\tqstart\\tqend\\tsstart\\tsend\\tevalue\\tbitscore\\tMAG1\\tMAG2\\tMAGqual1\\tMAGqual2\\tSubject1\\tSubject2\\tHostPair\\tANI\\tORFs\", file = CW_hits_ORF_file)\n",
    "\n",
    "for line in CW_hits_ORF:\n",
    "    print(line.strip(), file = CW_hits_ORF_file)\n",
    "\n",
    "CW_hits_ORF_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173bb376-ad8e-4a69-887e-4fbdc383438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Getting only farmer ORFs\n",
    "CW_hits_farmerORF = []\n",
    "\n",
    "for line in CW_hits_ORF:\n",
    "    line = line.split(\"\\t\")\n",
    "    entry = line[0:20]\n",
    "    ORFs = []\n",
    "    for ORF in line[20:]:\n",
    "        if ORF.startswith(\"W\"):\n",
    "            ORFs.append(ORF)\n",
    "    if len(ORFs) == 0:\n",
    "        ORFs.append(\"None\")\n",
    "    entry = entry + ORFs\n",
    "    CW_hits_farmerORF.append(\"\\t\".join(entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5430ef9-ec31-4fc6-80a6-a5cee2eea99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_hits_farmerORF_file = open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt_CW_farmerORFs_100cov.txt\", \"w\")\n",
    "\n",
    "print(\"Contig1\\tContig2\\tpident\\tlength\\tmismatch\\tgapopen\\tqstart\\tqend\\tsstart\\tsend\\tevalue\\tbitscore\\tMAG1\\tMAG2\\tMAGqual1\\tMAGqual2\\tSubject1\\tSubject2\\tHostPair\\tANI\\tORFs\", file = CW_hits_farmerORF_file)\n",
    "\n",
    "for line in CW_hits_farmerORF:\n",
    "    print(line, file = CW_hits_farmerORF_file)\n",
    "    \n",
    "CW_hits_farmerORF_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3150fd-855a-4a89-8804-ec7580a53fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Getting the DNA and AA sequences for the farmer ORFs\n",
    "DNA_seqs = open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/GOterm/230202_allFarmORFs_DNAseq.ffn\", \"w\")\n",
    "AA_seqs = open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/GOterm/230202_allFarmORFs_AAseq.faa\", \"w\")\n",
    "\n",
    "unique_ORFs = []\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt_CW_farmerORFs_100cov.txt\", \"r\"):\n",
    "    if line.startswith(\"Contig1\"):\n",
    "        continue\n",
    "    else:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        \n",
    "        if line[0].startswith(\"W\"):\n",
    "            MAG = line[12]\n",
    "        else:\n",
    "            MAG = line[13]\n",
    "        \n",
    "        if line[20] != \"None\":\n",
    "            for entry in line[20:]:\n",
    "                if entry not in unique_ORFs:\n",
    "                    unique_ORFs.append(entry)\n",
    "                    ORFID = entry.split(\",\")[2]\n",
    "                    path = \"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d25_bakta_HQMQ/\" + MAG + \"/\" + MAG\n",
    "                    \n",
    "                    seqs = open(path + \".faa\", \"r\")\n",
    "                    seqs = seqs.readlines()\n",
    "                    for i in range(0,len(seqs),2):\n",
    "                        if ORFID in seqs[i]:\n",
    "                            print(seqs[i].strip(), file = AA_seqs)\n",
    "                            print(seqs[i+1].strip(), file = AA_seqs)\n",
    "                            \n",
    "                    \n",
    "                    seqs = open(path + \".ffn\", \"r\")\n",
    "                    seqs = seqs.readlines()\n",
    "                    for i in range(0,len(seqs),2):\n",
    "                        if ORFID in seqs[i]:\n",
    "                            print(seqs[i].strip(), file = DNA_seqs)\n",
    "                            print(seqs[i+1].strip(), file = DNA_seqs)\n",
    "                            \n",
    "DNA_seqs.close()\n",
    "AA_seqs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce72239-8ddd-4485-82f3-27acb74c5a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_ORFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d5916a-e032-4375-acb6-f396d66535e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Setting up the files for chord diagrams\n",
    "CW_hits_chord = []\n",
    "\n",
    "CW_hits_families = {}\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt_CW_ARGs_100cov_uniqueORFs.txt\", \"r\"):\n",
    "    if line.startswith(\"Contig\"):\n",
    "        continue\n",
    "    else:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        contig1 = line[0]\n",
    "        contig2 = line[1]\n",
    "        \n",
    "        family1 = line[10]\n",
    "        family2 = line[17]\n",
    "        \n",
    "        if family1 not in CW_hits_families:\n",
    "            CW_hits_families[family1] = 1\n",
    "        else:\n",
    "            CW_hits_families[family1] += 1\n",
    "            \n",
    "        if family2 not in CW_hits_families:\n",
    "            CW_hits_families[family2] = 1\n",
    "        else:\n",
    "            CW_hits_families[family2] += 1\n",
    "        \n",
    "        if line[24] == \"None\":\n",
    "            ARGs = line[24]\n",
    "        else:\n",
    "            ARGs = \"Present\"\n",
    "        \n",
    "        families = line[20]\n",
    "        \n",
    "        if contig1.startswith(\"W\"):\n",
    "            family_W = contig1[0] + \"-\" + family1\n",
    "            family_C = contig2[0] + \"-\" + family2\n",
    "        else:\n",
    "            family_W = contig2[0] + family2\n",
    "            family_C = contig1[0] + family1\n",
    "            \n",
    "        CW_hits_chord.append(\"\\t\".join([family_W, family_C, family_W[2:], family_C[2:], families, ARGs]))\n",
    "        \n",
    "CW_hits_families = sorted(CW_hits_families.items(), key=lambda x:x[1], reverse=True)\n",
    "CW_hits_families = dict(CW_hits_families)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c34518-5725-4ebf-8f86-666cab52b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Getting the top 10 families represented in the identified hits\n",
    "CW_hits_top10families = list(dict(sorted(CW_hits_families.items(), key=lambda x:x[1], reverse=True)[:10]).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f3d493-5e8b-44f4-905a-b7d028d7e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_hits_top10families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e07cd0-a3cd-4d86-99de-ae810bed00d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_hits_chord_top10fam = []\n",
    "\n",
    "CW_hits_chord_top10fam.append(\"W_family_alt\\tC_family_alt\\tCount\\tW_family\\tC_family\\tFamilies\\tARG\")\n",
    "\n",
    "for line in CW_hits_chord:\n",
    "    line = line.split(\"\\t\")\n",
    "    family_W = line[2]\n",
    "    family_C = line[3]\n",
    "    families = line[4]\n",
    "    ARGs = line[5]\n",
    "    \n",
    "    if family_W in CW_hits_top10families:\n",
    "        family_W = \"W-\" + family_W\n",
    "    else:\n",
    "        family_W = \"W-Other\"\n",
    "        \n",
    "    if family_C in CW_hits_top10families:\n",
    "        family_C = \"C-\" + family_C\n",
    "    else:\n",
    "        family_C = \"C-Other\"\n",
    "        \n",
    "    CW_hits_chord_top10fam.append(\"\\t\".join([family_W, family_C, \"1\", family_W[2:], family_C[2:], families, ARGs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa729160-892b-463f-92c5-57ee0dbc21bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_hits_chord_top10fam_file = open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/ChordDiagram/CW_hitsBLASTn_top10families_ARG.txt\", \"w\")\n",
    "\n",
    "for line in CW_hits_chord_top10fam:\n",
    "    print(line, file = CW_hits_chord_top10fam_file)\n",
    "    \n",
    "CW_hits_chord_top10fam_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6dcf1c-a495-45cc-8cef-8af6f39de8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Setting up the file for the chord diagram of ARG-only hits\n",
    "ARGs_top10 = [\n",
    "    \"TETRACYCLINE\", \"TRIMETHOPRIM\", \"GLYCOPEPTIDE\", \"BETA.LACTAM\", \"LINCOSAMIDE\",\n",
    "    \"MACROLIDE\", \"PHENICOL\", \"QUINOLONE\", \"AMINOGLYCOSIDE\", \"FOSFOMYCIN\"\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdd1a01-1112-4cf5-9507-a55521c2f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARGs_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c3f48c-ea5f-43c8-9b9c-124716902897",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_hits_ARGonly_top10fam_chord = []\n",
    "\n",
    "CW_hits_ARGonly_top10fam_chord.append(\"W_family_alt\\tC_family_alt\\tCount\\tW_family\\tC_family\\tFamilies\\tARG\")\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt_CW_onlyARGs_100cov_uniqueORFs.txt\", \"r\"):\n",
    "    if line.startswith(\"Contig\"):\n",
    "        continue\n",
    "    else:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        contig1 = line[0]\n",
    "        contig2 = line[1]\n",
    "        \n",
    "        family1 = line[10]\n",
    "        family2 = line[17]\n",
    "        \n",
    "        if family1 not in CW_hits_top10families:\n",
    "            family1 = \"Other\"\n",
    "            \n",
    "        if family2 not in CW_hits_top10families:\n",
    "            family2 = \"Other\"\n",
    "        \n",
    "        if contig1.startswith(\"W\"):\n",
    "            family_W = \"W-\" + family1\n",
    "            family_C = \"C-\" + family2\n",
    "        else:\n",
    "            family_W = \"W-\" + family2\n",
    "            family_C = \"C-\" + family1\n",
    "            \n",
    "        families = line[20]\n",
    "        \n",
    "        ARGs = line[24:]\n",
    "        \n",
    "        for ARG in ARGs:\n",
    "            ARG = ARG.split(\",\")[0]\n",
    "            if ARG not in ARGs_top10:\n",
    "                ARG = \"Other\"\n",
    "            CW_hits_ARGonly_top10fam_chord.append(\"\\t\".join([family_W, family_C, \"1\", family_W[2:], family_C[2:], families, ARG]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6350dea-b9bd-487e-8237-b455ef8ee699",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_hits_ARGonly_top10fam_chord_file = open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/ChordDiagram/CW_hitsBLASTn_top10families_onlyARG.txt\", \"w\")\n",
    "\n",
    "for line in CW_hits_ARGonly_top10fam_chord:\n",
    "    print(line, file = CW_hits_ARGonly_top10fam_chord_file)\n",
    "    \n",
    "CW_hits_ARGonly_top10fam_chord_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec08279-e4e3-4312-8093-a31b29be76c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARGs_top3 = [\n",
    "    \"TETRACYCLINE\", \"LINCOSAMIDE\", \"MACROLIDE\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a7b6a2-026c-4ed5-baf4-47b6424d74ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_hits_top3ARGonly_top10fam_chord = []\n",
    "\n",
    "CW_hits_top3ARGonly_top10fam_chord.append(\"W_family_alt\\tC_family_alt\\tCount\\tW_family\\tC_family\\tFamilies\\tARG\")\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt_CW_onlyARGs_100cov_uniqueORFs.txt\", \"r\"):\n",
    "    if line.startswith(\"Contig\"):\n",
    "        continue\n",
    "    else:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        contig1 = line[0]\n",
    "        contig2 = line[1]\n",
    "        \n",
    "        family1 = line[10]\n",
    "        family2 = line[17]\n",
    "        \n",
    "        if family1 not in CW_hits_top10families:\n",
    "            family1 = \"Other\"\n",
    "            \n",
    "        if family2 not in CW_hits_top10families:\n",
    "            family2 = \"Other\"\n",
    "        \n",
    "        if contig1.startswith(\"W\"):\n",
    "            family_W = \"W-\" + family1\n",
    "            family_C = \"C-\" + family2\n",
    "        else:\n",
    "            family_W = \"W-\" + family2\n",
    "            family_C = \"C-\" + family1\n",
    "            \n",
    "        families = line[20]\n",
    "        \n",
    "        ARGs = line[24:]\n",
    "        \n",
    "        for ARG in ARGs:\n",
    "            ARG = ARG.split(\",\")[0]\n",
    "            if ARG not in ARGs_top3:\n",
    "                ARG = \"Other\"\n",
    "            CW_hits_top3ARGonly_top10fam_chord.append(\"\\t\".join([family_W, family_C, \"1\", family_W[2:], family_C[2:], families, ARG]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833145c5-1a5e-48fd-a255-9771714f9a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_hits_top3ARGonly_top10fam_chord_file = open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/ChordDiagram/CW_hitsBLASTn_top10families_onlyARGtop3.txt\", \"w\")\n",
    "\n",
    "for line in CW_hits_top3ARGonly_top10fam_chord:\n",
    "    print(line, file = CW_hits_top3ARGonly_top10fam_chord_file)\n",
    "    \n",
    "CW_hits_top3ARGonly_top10fam_chord_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d45d1fb-a928-48b7-8781-5ae58b60ccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Looking at the exact genes that were found in the shared fragments\n",
    "######First, creating a dictionary of the gene assignments for all ARG ORFIDs\n",
    "ARG_ORFs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b6d435-e1bc-4582-bce9-ec12796a77f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Looking at the exact genes that were found in the shared fragments\n",
    "######First, creating a dictionary of the gene assignments for all ARG ORFIDs\n",
    "ARG_ORFs = {}\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d12_shortbred_HQMQ/221230_shortBREDjoint_ORFID_v3.txt\", \"r\", errors=\"ignore\"):\n",
    "    if not line.startswith(\"MAG\"):\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        ARG = line[1]\n",
    "        ORFID = line[2].split(\" \")[0]\n",
    "        if len(ORFID) != 12:\n",
    "            ORFID = ORFID[1:]\n",
    "        ARG_ORFs[ORFID] = ARG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c652ae-a66b-4ea1-804c-230289bc6326",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Now (as above), parsing through the BLASTn to get the encoded ARGs\n",
    "CW_hits_ARG = []\n",
    "\n",
    "for line in CW_hits:\n",
    "    contig1 = line.split(\"\\t\")[0]\n",
    "    contig2 = line.split(\"\\t\")[1]\n",
    "    \n",
    "    start1 = int(line.split(\"\\t\")[6])\n",
    "    stop1 = int(line.split(\"\\t\")[7])\n",
    "    \n",
    "    if start1 > stop1:\n",
    "        temp = start1\n",
    "        start1 = stop1\n",
    "        stop1 = temp\n",
    "        \n",
    "    start2 = int(line.split(\"\\t\")[8])\n",
    "    stop2 = int(line.split(\"\\t\")[9])\n",
    "    \n",
    "    if start2 > stop2:\n",
    "        temp = start2\n",
    "        start2 = stop2\n",
    "        stop2 = temp\n",
    "    \n",
    "    ARGs = \"\"\n",
    "    \n",
    "    if contig1 not in contig_ARGcoordinates.keys() and contig2 not in contig_ARGcoordinates.keys():\n",
    "        CW_hits_ARG.append(line + \"\\tNone\")\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        if contig1 in contig_ARGcoordinates.keys():\n",
    "            for i in range(len(contig_ARGcoordinates[contig1])):\n",
    "                start = int(contig_ARGcoordinates[contig1][i].split(\"\\t\")[0])\n",
    "                stop = int(contig_ARGcoordinates[contig1][i].split(\"\\t\")[1])\n",
    "                cov = 0\n",
    "\n",
    "                if start > stop:\n",
    "                    temp = start\n",
    "                    start = stop\n",
    "                    stop = temp\n",
    "\n",
    "                if start > start1 and start < stop1 and stop > start1 and stop < stop1:\n",
    "                    cov = 100\n",
    "                elif start > start1 and start < stop1 and stop > start1 and stop > stop1:\n",
    "                    cov = (stop1 - start)/(stop - start)\n",
    "                    cov = round(cov * 100)\n",
    "                elif start < start1 and start < stop1 and stop > start1 and stop < stop1:\n",
    "                    cov = (stop - start1)/(stop - start)\n",
    "                    cov = round(cov * 100)\n",
    "                elif start < start1 and start < stop1 and stop > start1 and stop > stop1:\n",
    "                    cov = (stop1 - start1)/(stop - start)\n",
    "                    cov = round(cov * 100)\n",
    "                else:\n",
    "                    cov = 0\n",
    "                    \n",
    "                if cov == 100:\n",
    "                    if ARGs == \"\":\n",
    "                        ARGs = contig1 + \",\" + ARG_ORFs[contig_ARGORFID[contig1][i]] + \",\" + contig_abxClasses[contig1][i] + \",\" + contig_ARGannot[contig1][i] + \",\" + str(cov)\n",
    "                    else:\n",
    "                        ARGs = ARGs + \"\\t\" + contig1 + \",\" + ARG_ORFs[contig_ARGORFID[contig1][i]] + \",\" + contig_abxClasses[contig1][i] + \",\" + contig_ARGannot[contig1][i] + \",\" + str(cov)\n",
    "                        \n",
    "        if contig2 in contig_ARGcoordinates.keys():\n",
    "            for i in range(len(contig_ARGcoordinates[contig2])):\n",
    "                start = int(contig_ARGcoordinates[contig2][i].split(\"\\t\")[0])\n",
    "                stop = int(contig_ARGcoordinates[contig2][i].split(\"\\t\")[1])\n",
    "                cov = 0\n",
    "\n",
    "                if start > stop:\n",
    "                    temp = start\n",
    "                    start = stop\n",
    "                    stop = temp\n",
    "\n",
    "                if start > start2 and start < stop2 and stop > start2 and stop < stop2:\n",
    "                    cov = 100\n",
    "                elif start > start2 and start < stop2 and stop > start2 and stop > stop2:\n",
    "                    cov = (stop2 - start)/(stop - start)\n",
    "                    cov = round(cov * 100)\n",
    "                elif start < start2 and start < stop2 and stop > start2 and stop < stop2:\n",
    "                    cov = (stop - start2)/(stop - start)\n",
    "                    cov = round(cov * 100)\n",
    "                elif start < start2 and start < stop2 and stop > start2 and stop > stop2:\n",
    "                    cov = (stop2 - start2)/(stop - start)\n",
    "                    cov = round(cov * 100)\n",
    "                else:\n",
    "                    cov = 0\n",
    "                    \n",
    "                if cov == 100:\n",
    "                    if ARGs == \"\":\n",
    "                        ARGs = contig2 + \",\" + ARG_ORFs[contig_ARGORFID[contig2][i]] + \",\" + contig_abxClasses[contig2][i] + \",\" + contig_ARGannot[contig2][i] + \",\" + str(cov)\n",
    "                    else:\n",
    "                        ARGs = ARGs + \"\\t\" + contig2 + \",\" + ARG_ORFs[contig_ARGORFID[contig2][i]] + \",\" + contig_abxClasses[contig2][i] + \",\" + contig_ARGannot[contig2][i] + \",\" + str(cov)\n",
    "                        \n",
    "        if ARGs == \"\":\n",
    "            CW_hits_ARG.append(line + \"\\tNone\")\n",
    "        else:\n",
    "            CW_hits_ARG.append(line + \"\\t\" + ARGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078193ed-f932-4e2f-9ea5-2baba530bdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_hits_ARG_file = open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt_CW_ARGs_ShortbredIDs_100cov.txt\", \"w\")\n",
    "\n",
    "print(\"Contig1\\tContig2\\tpident\\tlength\\tmismatch\\tgapopen\\tqstart\\tqend\\tsstart\\tsend\\tevalue\\tbitscore\\tMAG1\\tMAG2\\tMAGqual1\\tMAGqual2\\tSubject1\\tSubject2\\tHostPair\\tANI\\tARGs\", file = CW_hits_ARG_file)\n",
    "\n",
    "for line in CW_hits_ARG:\n",
    "    print(line.strip(), file = CW_hits_ARG_file)\n",
    "\n",
    "CW_hits_ARG_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6ab307-6217-4189-bc7e-91df29d44bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Checking to see if the ARGs have the same annotations across different samples\n",
    "annot_ARGs = {}\n",
    "\n",
    "for line in CW_hits_ARG:\n",
    "    line = line.split(\"\\t\")\n",
    "    if line[-1] != \"None\":\n",
    "        ARGs = line[20:]\n",
    "        for hit in ARGs:\n",
    "            hit = hit.split(\",\")\n",
    "            ARG = hit[1]\n",
    "            annot = hit[3]\n",
    "            if ARG in annot_ARGs.keys() and annot not in annot_ARGs[ARG]:\n",
    "                annot_ARGs[ARG].append(annot)\n",
    "            else:\n",
    "                annot_ARGs[ARG] = [annot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9628b509-6b59-4289-8ff4-20c0de2aaaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(annot_ARGs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c44e7f-ccfe-4c4b-823d-90ac84fad109",
   "metadata": {},
   "outputs": [],
   "source": [
    "###For many shared fragments, matching ARGs were identified from both the query and the subject, which is great and expected\n",
    "###Now going thorugh the entries to keep only unique ARG-matched ORFs for each BLAST hit\n",
    "CW_ARGs_unique = []\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt_CW_ARGs_ShortbredIDs_100cov.txt\", \"r\"):\n",
    "    if line.startswith(\"Contig1\"):\n",
    "        continue\n",
    "    else:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        \n",
    "        contig1 = line[0]\n",
    "        contig2 = line[1]\n",
    "        \n",
    "        pident = line[2]\n",
    "        length = line[3]\n",
    "        \n",
    "        MAG1 = line[12]\n",
    "        MAG2 = line[13]\n",
    "        \n",
    "        taxa1 = MAG_taxa[MAG1]\n",
    "        taxa1 = taxa1.split(\";\")\n",
    "        domain1 = taxa1[0]\n",
    "        phylum1 = taxa1[1]\n",
    "        class1 = taxa1[2]\n",
    "        order1 = taxa1[3]\n",
    "        family1 = taxa1[4]\n",
    "        genus1 = taxa1[5]\n",
    "        species1 = taxa1[6]\n",
    "        \n",
    "        taxa2 = MAG_taxa[MAG2]\n",
    "        taxa2 = taxa2.split(\";\")\n",
    "        domain2 = taxa2[0]\n",
    "        phylum2 = taxa2[1]\n",
    "        class2 = taxa2[2]\n",
    "        order2 = taxa2[3]\n",
    "        family2 = taxa2[4]\n",
    "        genus2 = taxa2[5]\n",
    "        species2 = taxa2[6]\n",
    "        \n",
    "        if family1 == family2:\n",
    "            families = \"Same family\"\n",
    "        else:\n",
    "            families = \"Different families\"\n",
    "            \n",
    "        if genus1 == genus2:\n",
    "            genera = \"Same genera\"\n",
    "        else:\n",
    "            genera = \"Different genera\"\n",
    "        \n",
    "        subject1 = line[16]\n",
    "        subject2 = line[17]\n",
    "        \n",
    "        ARGs = line[20:]\n",
    "        \n",
    "        if line[-1] == \"None\":\n",
    "            CW_ARGs_unique.append(\"\\t\".join([contig1, contig2, pident, length, MAG1, MAG2, domain1, phylum1, class1, order1, family1, genus1, species1, domain2, phylum2, class2, order2, family2, genus2, species2, families, genera, subject1, subject2, line[-1]]))\n",
    "        else:\n",
    "            unique_ORFs = []\n",
    "            unique_entries = []\n",
    "            \n",
    "            for item in ARGs:\n",
    "                item = item.split(\",\")\n",
    "                ARG = item[1]\n",
    "                ARGclass = item[2]\n",
    "                ORF = item[3]\n",
    "                if ORF not in unique_ORFs:\n",
    "                    unique_entries.append(f\"{ARG}, {ARGclass}, {ORF}\")\n",
    "                    unique_ORFs.append(ORF)\n",
    "            \n",
    "            unique_entries = \"\\t\".join(unique_entries)\n",
    "            CW_ARGs_unique.append(\"\\t\".join([contig1, contig2, pident, length, MAG1, MAG2, domain1, phylum1, class1, order1, family1, genus1, species1, domain2, phylum2, class2, order2, family2, genus2, species2, families, genera, subject1, subject2, unique_entries]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf30908-7b81-4f0c-aed2-612ba3ef813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_ARGs_unique_file = open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt_CW_ARGs_ShortbredIDs_100cov_uniqueORFs.txt\", \"w\")\n",
    "CW_onlyARGs_unique_file = open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt_CW_onlyARGs_ShortbredIDs_100cov_uniqueORFs.txt\", \"w\")\n",
    "\n",
    "print(\"Contig1\\tContig2\\tpident\\tlength\\tMAG1\\tMAG2\\tDomain1\\tPhylum1\\tClass1\\tOrder1\\tFamily1\\tGenus1\\tSpecies1\\tDomain2\\tPhylum2\\tClass2\\tOrder2\\tFamily2\\tGenus2\\tSpecies2\\tFamilies\\tGenera\\tSubject1\\tSubject2\\tARGs\", file = CW_ARGs_unique_file)\n",
    "print(\"Contig1\\tContig2\\tpident\\tlength\\tMAG1\\tMAG2\\tDomain1\\tPhylum1\\tClass1\\tOrder1\\tFamily1\\tGenus1\\tSpecies1\\tDomain2\\tPhylum2\\tClass2\\tOrder2\\tFamily2\\tGenus2\\tSpecies2\\tFamilies\\tGenera\\tSubject1\\tSubject2\\tARGs\", file = CW_onlyARGs_unique_file)\n",
    "\n",
    "for line in CW_ARGs_unique:\n",
    "    print(line, file = CW_ARGs_unique_file)\n",
    "    if line.split(\"\\t\")[-1] != \"None\":\n",
    "        print(line, file = CW_onlyARGs_unique_file)\n",
    "        \n",
    "CW_ARGs_unique_file.close()\n",
    "CW_onlyARGs_unique_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f06a83d-aadb-43de-a4bd-4194e7fd28f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Looking at the genes found in the shared fragments\n",
    "sharedARGs = {}\n",
    "\n",
    "for line in CW_ARGs_unique:\n",
    "    if line.split(\"\\t\")[-1] != \"None\":\n",
    "        ARGs = line.split(\"\\t\")[24:]\n",
    "        for item in ARGs:\n",
    "            ARG = item.split(\",\")[0]\n",
    "            if ARG in sharedARGs.keys():\n",
    "                sharedARGs[ARG] += 1\n",
    "            else:\n",
    "                sharedARGs[ARG] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b5e5d5-beaa-422a-9a39-7c847951383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharedARGs = sorted(sharedARGs.items(), key=lambda x:x[1], reverse=True)\n",
    "sharedARGs = dict(sharedARGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3215e8-2377-41ed-87b9-5c343c9b1aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharedARGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e06063f-80bd-44af-99f1-9a88ec781088",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARGs_enrichedCows = [\n",
    "    'DOME_01131|P1-TE_215|gene-1|+|119-1828|complete',\n",
    "    '1028097032|WP_063853729_1|1|1|mef(En2)|mef(En2)|efflux|2|MACROLIDE|MACROLIDE|macrolide_efflux_MFS_transporter_Mef(En2)',\n",
    "    '490437755|WP_004308783_1|1|1|lnu(AN2)|lnu(AN2)|nucleotidyltransferase|2|LINCOSAMIDE|LINCOSAMIDE|lincosamide_nucleotidyltransferase_Lnu(AN2)',\n",
    "    'DLFM02_02210|F11_TET_3|gene-3|+|2650-3888|complete',\n",
    "    'DLFM11_01245|P17SR4_AZM_210|gene-1|+|88-1308|complete',\n",
    "    '1988761213|WP_204313008_1|1|1|tet(O_W)|tet(O_W)||2|TETRACYCLINE|TETRACYCLINE|tetracycline_resistance_ribosomal_protection_mosaic_protein_Tet(O_W)',\n",
    "    'DLFM04_00595|Control-TwinA-Time3_TET_5|gene-3|-|814-2751|complete',\n",
    "    'DOME_01137|P1-TE_226|gene-2|-|345-695|complete',\n",
    "    '493486205|WP_006440994_1|1|1|tetA(P)|tetA(P)|efflux|2|TETRACYCLINE|TETRACYCLINE|tetracycline_efflux_MFS_transporter_TetA(P)',\n",
    "    'DOME_04541|P7-TE_16|gene-1|-|111-2114|complete',\n",
    "    'DOME_01229|P2-TE_57|gene-1|-|21-269|complete',\n",
    "    '501051336|WP_012102963_1|1|1|mef(A)|mef(A)|efflux|2|ERYTHROMYCIN|MACROLIDE|macrolide_efflux_MFS_transporter_Mef(A)',\n",
    "    'DOME_03937|P6-TE_49|gene-2|-|215-1075|complete',\n",
    "    'DOME_05739|P5-CH_170|gene-1|-|28-813|complete',\n",
    "    'DLFM07_04648|08X-000_TET_14|gene-3|-|1360-3279|complete',\n",
    "    'DOME_02841|P4-GE_66|gene-2|-|631-1422|complete'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d525d-9db1-4623-9f8f-82eb431b084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "counter = 0\n",
    "\n",
    "for line in CW_ARGs_unique:\n",
    "    enriched = False\n",
    "    if line.split(\"\\t\")[-1] != \"None\":\n",
    "        total += 1\n",
    "        ARGs = line.split(\"\\t\")[24:]\n",
    "        for item in ARGs:\n",
    "            ARG = item.split(\",\")[0]\n",
    "            if ARG in ARGs_enrichedCows:\n",
    "                enriched = True\n",
    "    if enriched == True:\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e30145-663a-48a6-bacd-c2ff1d8e2f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd7269-ffc7-4bfd-bf2f-336ca3bc4035",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb462b0f-acff-4c38-9b5f-357d3526b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharedARGs_file = open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/CW_100cov_sharedARGs.txt\", \"w\")\n",
    "\n",
    "for key in sharedARGs.keys():\n",
    "    print(key, file = sharedARGs_file)\n",
    "    \n",
    "sharedARGs_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b58fc84-297e-4b0f-9ffc-2c07ac3ff0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharedARGs_enrichedCows_file = open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/CW_100cov_sharedARGs_EnrichedInCows.txt\", \"w\")\n",
    "\n",
    "for item in ARGs_enrichedCows:\n",
    "    print(item, file = sharedARGs_enrichedCows_file)\n",
    "    \n",
    "sharedARGs_enrichedCows_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef79f58-402e-4c95-b8e8-f103b34b0fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Making a chrod diagram only for ARGs that are enriched in the cow gut\n",
    "CW_hits_top3CowEnrichedARGonly_top10fam_chord = []\n",
    "\n",
    "CW_hits_top3CowEnrichedARGonly_top10fam_chord.append(\"W_family_alt\\tC_family_alt\\tCount\\tW_family\\tC_family\\tFamilies\\tARG\")\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt_CW_onlyARGs_ShortbredIDs_100cov_uniqueORFs.txt\", \"r\"):\n",
    "    if line.startswith(\"Contig\"):\n",
    "        continue\n",
    "    else:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        contig1 = line[0]\n",
    "        contig2 = line[1]\n",
    "        \n",
    "        family1 = line[10]\n",
    "        family2 = line[17]\n",
    "        \n",
    "        if family1 not in CW_hits_top10families:\n",
    "            family1 = \"Other\"\n",
    "            \n",
    "        if family2 not in CW_hits_top10families:\n",
    "            family2 = \"Other\"\n",
    "        \n",
    "        if contig1.startswith(\"W\"):\n",
    "            family_W = \"W-\" + family1\n",
    "            family_C = \"C-\" + family2\n",
    "        else:\n",
    "            family_W = \"W-\" + family2\n",
    "            family_C = \"C-\" + family1\n",
    "            \n",
    "        families = line[20]\n",
    "        \n",
    "        ARGs = line[24:]\n",
    "        \n",
    "        for ARG in ARGs:\n",
    "            ARG = ARG.strip().split(\",\")\n",
    "            gene = ARG[0].strip()\n",
    "            abx_class = ARG[1].strip()\n",
    "            if gene in ARGs_enrichedCows:\n",
    "                if abx_class not in ARGs_top3:\n",
    "                    abx_class = \"Other\"\n",
    "                CW_hits_top3CowEnrichedARGonly_top10fam_chord.append(\"\\t\".join([family_W, family_C, \"1\", family_W[2:], family_C[2:], families, abx_class]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aa6401-8ca0-47a4-abc8-6bac59b3d4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_hits_top3CowEnrichedARGonly_top10fam_chord_file = open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/ChordDiagram/CW_hitsBLASTn_top10families_onlyCowEnrichedARGtop3.txt\", \"w\")\n",
    "\n",
    "for line in CW_hits_top3CowEnrichedARGonly_top10fam_chord:\n",
    "    print(line, file = CW_hits_top3CowEnrichedARGonly_top10fam_chord_file)\n",
    "    \n",
    "CW_hits_top3CowEnrichedARGonly_top10fam_chord_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e771ae-6e2b-4512-9db9-246b9e254749",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Looking at where ARGs are enriched within the shared fragments relative to their prevalence in the MAGs\n",
    "######Getting the count of all unique ORFs found in the shared fragments\n",
    "sharedORFcount = 0\n",
    "\n",
    "unique_hits = []\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt_CW_farmerORFs_100cov.txt\", \"r\"):\n",
    "    if not line.startswith(\"Contig1\"):\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        ORFs = line[20:]\n",
    "        for ORF in ORFs:\n",
    "            if ORF not in unique_hits and ORF != \"None\":\n",
    "                unique_hits.append(ORF)\n",
    "                \n",
    "sharedORFcount = len(unique_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37498341-b213-41cb-9f63-5398831623bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Then, getting the count of all unique ARGs found in the shared fragments\n",
    "sharedARGcount = 0\n",
    "\n",
    "unique_hits = []\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt_CW_ARGs_100cov.txt\", \"r\"):\n",
    "    if not line.startswith(\"Contig1\"):\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        ORFs = line[20:]\n",
    "        for ORF in ORFs:\n",
    "            if ORF not in unique_hits and ORF != \"None\" and ORF.startswith(\"W\"):\n",
    "                unique_hits.append(ORF)\n",
    "                \n",
    "sharedARGcount = len(unique_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cd8ee0-3f2e-476d-98fd-7b9d29007ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Then, getting the count of all unique ORFs found in the farmer MAGs\n",
    "shared_farmer_MAGs = []\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt_CW_farmerORFs_100cov.txt\", \"r\"):\n",
    "    if not line.startswith(\"Contig1\"):\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        if line[0].startswith(\"W\"):\n",
    "            MAG = line[12]\n",
    "        else:\n",
    "            MAG = line[13]\n",
    "        \n",
    "        if MAG not in shared_farmer_MAGs:\n",
    "            shared_farmer_MAGs.append(MAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37bd239-dd3a-4132-a9f7-7adb18f2127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "allORFcounts = 0\n",
    "\n",
    "for MAG in shared_farmer_MAGs:\n",
    "    file = \"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d25_bakta_HQMQ/\" + MAG + \"/\" + MAG + \".faa\"\n",
    "    file = open(file, \"r\")\n",
    "    file = file.readlines()\n",
    "    allORFcounts += len(file)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd160c5-ca7d-4bec-9e9c-e7d5ff6be511",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Then, getting the count of all unique ARGs found in the farmer MAGs\n",
    "allARGcounts = 0\n",
    "\n",
    "MAG_ARG_combos = []\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d12_shortbred_HQMQ/joint_HQMQ_output.txt\", \"r\"):\n",
    "    if not line.startswith(\"MAG\"):\n",
    "        MAG = line.strip().split(\"\\t\")[0]\n",
    "        if MAG in shared_farmer_MAGs:\n",
    "            if \"#\" not in line:\n",
    "                allARGcounts += 1\n",
    "            else:\n",
    "                hit = line.strip().split(\"\\t\")[1]\n",
    "                hit = hit.split(\"_#\")[0]\n",
    "                combo = MAG + \"-\" + hit\n",
    "                if combo not in MAG_ARG_combos:\n",
    "                    MAG_ARG_combos.append(combo)\n",
    "                    allARGcounts += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fce987-e9ee-4dd1-a917-b6bb6a79e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(allORFcounts)\n",
    "print(allARGcounts)\n",
    "print(sharedORFcount)\n",
    "print(sharedARGcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824e5ccd-6ca9-4515-b0b6-592e986b6e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_counts = [[(allORFcounts - allARGcounts - sharedORFcount + sharedARGcount), (allARGcounts - sharedARGcount)],\n",
    "              [(sharedORFcount - sharedARGcount), sharedARGcount]]\n",
    "\n",
    "chi2_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc6ed2c-8e9f-44df-8a5d-1435489ce303",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_contingency(chi2_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "472ad2ba-0cea-4c65-93be-b85d4a8c5b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Looking at microbial families where the MefLnu cassette was found\n",
    "cow_MAGs = []\n",
    "cow_families = {}\n",
    "\n",
    "farmer_MAGs = []\n",
    "farmer_families = {}\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt_CW_onlyARGs_ShortbredIDs_100cov_uniqueORFs.txt\"):\n",
    "    if not line.startswith(\"Contig1\"):\n",
    "        if \"mef(En2)\" in line and \"Lnu(AN2)\" in line:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            farmer_MAG = line[4]\n",
    "            cow_MAG = line[5]\n",
    "            farmer_family = line[10]\n",
    "            cow_family = line[17]\n",
    "            if cow_MAG not in cow_MAGs:\n",
    "                cow_MAGs.append(cow_MAG)\n",
    "                \n",
    "                if cow_family not in cow_families.keys():\n",
    "                    cow_families[cow_family] = 1\n",
    "                else:\n",
    "                    cow_families[cow_family] += 1\n",
    "                    \n",
    "            if farmer_MAG not in farmer_MAGs:\n",
    "                farmer_MAGs.append(farmer_MAG)\n",
    "                \n",
    "                if farmer_family not in farmer_families.keys():\n",
    "                    farmer_families[farmer_family] = 1\n",
    "                else:\n",
    "                    farmer_families[farmer_family] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8e81442-3107-43eb-bef9-609f124ec098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f__Paludibacteraceae': 1,\n",
       " 'f__Lachnospiraceae': 8,\n",
       " 'f__P3': 2,\n",
       " 'f__Bacteroidaceae': 3}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cow_families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6816fb46-0cfe-4f0d-bbfe-40d8e7efc837",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Doing all of the above but for office worker and cows now\n",
    "###First gettin all of the BLAST hits between office workers and cows\n",
    "CD_hits = []\n",
    "\n",
    "for line in open(\"/Users/bejanmahmud/Library/CloudStorage/Box-Box/Bejan's files/Projects/DOME/DOME/Analysis/Metagenome/220221_DOME_fc_all/d22_BLASTn_HQMQ/joint_BLASTn_allHQMQMAGs_nodup_annot_filt.txt\", \"r\"):\n",
    "    if line.startswith(\"Contig1\"):\n",
    "        continue\n",
    "    else:\n",
    "        line = line.strip()\n",
    "        if \"C-D\" in line:\n",
    "            CD_hits.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b402d4d-f599-4f55-a4e1-c2dd7b0fb016",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Now (as above), parsing through the BLASTn to get the encoded ARGs\n",
    "CD_hits_ARG = []\n",
    "\n",
    "for line in CD_hits:\n",
    "    contig1 = line.split(\"\\t\")[0]\n",
    "    contig2 = line.split(\"\\t\")[1]\n",
    "    \n",
    "    start1 = int(line.split(\"\\t\")[6])\n",
    "    stop1 = int(line.split(\"\\t\")[7])\n",
    "    \n",
    "    if start1 > stop1:\n",
    "        temp = start1\n",
    "        start1 = stop1\n",
    "        stop1 = temp\n",
    "        \n",
    "    start2 = int(line.split(\"\\t\")[8])\n",
    "    stop2 = int(line.split(\"\\t\")[9])\n",
    "    \n",
    "    if start2 > stop2:\n",
    "        temp = start2\n",
    "        start2 = stop2\n",
    "        stop2 = temp\n",
    "    \n",
    "    ARGs = \"\"\n",
    "    \n",
    "    if contig1 not in contig_ARGcoordinates.keys() and contig2 not in contig_ARGcoordinates.keys():\n",
    "        CD_hits_ARG.append(line + \"\\tNone\")\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        if contig1 in contig_ARGcoordinates.keys():\n",
    "            for i in range(len(contig_ARGcoordinates[contig1])):\n",
    "                start = int(contig_ARGcoordinates[contig1][i].split(\"\\t\")[0])\n",
    "                stop = int(contig_ARGcoordinates[contig1][i].split(\"\\t\")[1])\n",
    "                cov = 0\n",
    "\n",
    "                if start > stop:\n",
    "                    temp = start\n",
    "                    start = stop\n",
    "                    stop = temp\n",
    "\n",
    "                if start > start1 and start < stop1 and stop > start1 and stop < stop1:\n",
    "                    cov = 100\n",
    "                elif start > start1 and start < stop1 and stop > start1 and stop > stop1:\n",
    "                    cov = (stop1 - start)/(stop - start)\n",
    "                    cov = round(cov * 100)\n",
    "                elif start < start1 and start < stop1 and stop > start1 and stop < stop1:\n",
    "                    cov = (stop - start1)/(stop - start)\n",
    "                    cov = round(cov * 100)\n",
    "                elif start < start1 and start < stop1 and stop > start1 and stop > stop1:\n",
    "                    cov = (stop1 - start1)/(stop - start)\n",
    "                    cov = round(cov * 100)\n",
    "                else:\n",
    "                    cov = 0\n",
    "                    \n",
    "                if cov == 100:\n",
    "                    if ARGs == \"\":\n",
    "                        ARGs = contig1 + \",\" + ARG_ORFs[contig_ARGORFID[contig1][i]] + \",\" + contig_abxClasses[contig1][i] + \",\" + contig_ARGannot[contig1][i] + \",\" + str(cov)\n",
    "                    else:\n",
    "                        ARGs = ARGs + \"\\t\" + contig1 + \",\" + ARG_ORFs[contig_ARGORFID[contig1][i]] + \",\" + contig_abxClasses[contig1][i] + \",\" + contig_ARGannot[contig1][i] + \",\" + str(cov)\n",
    "                        \n",
    "        if contig2 in contig_ARGcoordinates.keys():\n",
    "            for i in range(len(contig_ARGcoordinates[contig2])):\n",
    "                start = int(contig_ARGcoordinates[contig2][i].split(\"\\t\")[0])\n",
    "                stop = int(contig_ARGcoordinates[contig2][i].split(\"\\t\")[1])\n",
    "                cov = 0\n",
    "\n",
    "                if start > stop:\n",
    "                    temp = start\n",
    "                    start = stop\n",
    "                    stop = temp\n",
    "\n",
    "                if start > start2 and start < stop2 and stop > start2 and stop < stop2:\n",
    "                    cov = 100\n",
    "                elif start > start2 and start < stop2 and stop > start2 and stop > stop2:\n",
    "                    cov = (stop2 - start)/(stop - start)\n",
    "                    cov = round(cov * 100)\n",
    "                elif start < start2 and start < stop2 and stop > start2 and stop < stop2:\n",
    "                    cov = (stop - start2)/(stop - start)\n",
    "                    cov = round(cov * 100)\n",
    "                elif start < start2 and start < stop2 and stop > start2 and stop > stop2:\n",
    "                    cov = (stop2 - start2)/(stop - start)\n",
    "                    cov = round(cov * 100)\n",
    "                else:\n",
    "                    cov = 0\n",
    "                    \n",
    "                if cov == 100:\n",
    "                    if ARGs == \"\":\n",
    "                        ARGs = contig2 + \",\" + ARG_ORFs[contig_ARGORFID[contig2][i]] + \",\" + contig_abxClasses[contig2][i] + \",\" + contig_ARGannot[contig2][i] + \",\" + str(cov)\n",
    "                    else:\n",
    "                        ARGs = ARGs + \"\\t\" + contig2 + \",\" + ARG_ORFs[contig_ARGORFID[contig2][i]] + \",\" + contig_abxClasses[contig2][i] + \",\" + contig_ARGannot[contig2][i] + \",\" + str(cov)\n",
    "                        \n",
    "        if ARGs == \"\":\n",
    "            CD_hits_ARG.append(line + \"\\tNone\")\n",
    "        else:\n",
    "            CD_hits_ARG.append(line + \"\\t\" + ARGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6332ad64-2c12-4a41-9bea-6968c6a0c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Now going thorugh the entries to keep only unique ARG-matched ORFs for each BLAST hit\n",
    "CD_ARGs_unique = []\n",
    "\n",
    "for line in CD_hits_ARG:\n",
    "    line = line.strip().split(\"\\t\")\n",
    "\n",
    "    contig1 = line[0]\n",
    "    contig2 = line[1]\n",
    "\n",
    "    pident = line[2]\n",
    "    length = line[3]\n",
    "\n",
    "    MAG1 = line[12]\n",
    "    MAG2 = line[13]\n",
    "\n",
    "    taxa1 = MAG_taxa[MAG1]\n",
    "    taxa1 = taxa1.split(\";\")\n",
    "    domain1 = taxa1[0]\n",
    "    phylum1 = taxa1[1]\n",
    "    class1 = taxa1[2]\n",
    "    order1 = taxa1[3]\n",
    "    family1 = taxa1[4]\n",
    "    genus1 = taxa1[5]\n",
    "    species1 = taxa1[6]\n",
    "\n",
    "    taxa2 = MAG_taxa[MAG2]\n",
    "    taxa2 = taxa2.split(\";\")\n",
    "    domain2 = taxa2[0]\n",
    "    phylum2 = taxa2[1]\n",
    "    class2 = taxa2[2]\n",
    "    order2 = taxa2[3]\n",
    "    family2 = taxa2[4]\n",
    "    genus2 = taxa2[5]\n",
    "    species2 = taxa2[6]\n",
    "\n",
    "    if family1 == family2:\n",
    "        families = \"Same family\"\n",
    "    else:\n",
    "        families = \"Different families\"\n",
    "\n",
    "    if genus1 == genus2:\n",
    "        genera = \"Same genera\"\n",
    "    else:\n",
    "        genera = \"Different genera\"\n",
    "\n",
    "    subject1 = line[16]\n",
    "    subject2 = line[17]\n",
    "\n",
    "    ARGs = line[20:]\n",
    "\n",
    "    if line[-1] == \"None\":\n",
    "        CD_ARGs_unique.append(\"\\t\".join([contig1, contig2, pident, length, MAG1, MAG2, domain1, phylum1, class1, order1, family1, genus1, species1, domain2, phylum2, class2, order2, family2, genus2, species2, families, genera, subject1, subject2, line[-1]]))\n",
    "    else:\n",
    "        unique_ORFs = []\n",
    "        unique_entries = []\n",
    "\n",
    "        for item in ARGs:\n",
    "            item = item.split(\",\")\n",
    "            ARG = item[1]\n",
    "            ARGclass = item[2]\n",
    "            ORF = item[3]\n",
    "            if ORF not in unique_ORFs:\n",
    "                unique_entries.append(f\"{ARG}, {ARGclass}, {ORF}\")\n",
    "                unique_ORFs.append(ORF)\n",
    "\n",
    "        unique_entries = \"\\t\".join(unique_entries)\n",
    "        CD_ARGs_unique.append(\"\\t\".join([contig1, contig2, pident, length, MAG1, MAG2, domain1, phylum1, class1, order1, family1, genus1, species1, domain2, phylum2, class2, order2, family2, genus2, species2, families, genera, subject1, subject2, unique_entries]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39f68f4-8a91-444d-9d92-4882927b2427",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Looking at the genes found in the shared fragments\n",
    "sharedARGs_CD = {}\n",
    "\n",
    "for line in CD_ARGs_unique:\n",
    "    if line.split(\"\\t\")[-1] != \"None\":\n",
    "        ARGs = line.split(\"\\t\")[24:]\n",
    "        for item in ARGs:\n",
    "            ARG = item.split(\",\")[0]\n",
    "            if ARG in sharedARGs_CD.keys():\n",
    "                sharedARGs_CD[ARG] += 1\n",
    "            else:\n",
    "                sharedARGs_CD[ARG] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a04a97a-0e7c-4184-accc-c1ed2fc800df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharedARGs_CD = sorted(sharedARGs_CD.items(), key=lambda x:x[1], reverse=True)\n",
    "sharedARGs_CD = dict(sharedARGs_CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c9b5d0-e4c1-44c0-a886-ea43fb9b25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharedARGs_CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d6fa6f-3c99-4a24-9483-95787fdd1c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARGs_enrichedCows = ARGs_enrichedCows + [\"DOME_00805|P6-CH_34|gene-2|-|603-1037|complete\", \"DOME_05731|P5-CH_149|gene-1|-|298-708|complete\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a223d3e-7915-44ee-81b5-9d9d0365882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARGs_enrichedCows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683f7143-36a6-4530-afd0-9fcab165c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "total = 0\n",
    "\n",
    "for key, value in sharedARGs_CD.items():\n",
    "    total += value\n",
    "    if key in ARGs_enrichedCows:\n",
    "        counter += value\n",
    "        \n",
    "counter/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec39e84-9590-46f7-8adf-dc0d8d4ab6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532ee1fe-31b7-48cd-bd8f-1aa9e8976df7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
